{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxro_0g0Hsj0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4mqvWBzH3VO"
   },
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 150\n",
    "def get_training_data(data_dir):\n",
    "    images = []\n",
    "    labels_list = []\n",
    "\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                images.append(resized_arr)\n",
    "                labels_list.append(class_num)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "    # Convert to numpy arrays with proper shapes\n",
    "    X = np.array(images).reshape(-1, img_size, img_size, 1)  # Add channel dimension\n",
    "    y = np.array(labels_list)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mu6G32ccH3Y7"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/train')\n",
    "X_test, y_test = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/test')\n",
    "X_val, y_val = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYtLv74xH3bs"
   },
   "outputs": [],
   "source": [
    "# For visualization only, create string labels\n",
    "label_names = []\n",
    "for label in y_train:\n",
    "    if label == 0:\n",
    "        label_names.append(\"Pneumonia\")\n",
    "    else:\n",
    "        label_names.append(\"Normal\")\n",
    "\n",
    "# Convert to pandas Series for better compatibility with seaborn\n",
    "import pandas as pd\n",
    "label_series = pd.Series(label_names, name=\"Diagnosis\")\n",
    "\n",
    "# Plot using the string labels\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x=label_series)  # Use x= parameter to specify the data\n",
    "plt.title(\"Distribution of Training Data\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZl5G__aH3pF"
   },
   "outputs": [],
   "source": [
    "# Display the first image in the training set\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(X_train[0].reshape(img_size, img_size), cmap='gray')  # Reshape to remove the channel dimension\n",
    "plt.title(labels[y_train[0]])\n",
    "\n",
    "# Display the last image in the training set\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(X_train[-1].reshape(img_size, img_size), cmap='gray')\n",
    "plt.title(labels[y_train[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtanUTAUH3r2"
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = np.array(X_train) / 255\n",
    "x_val = np.array(X_val) / 255\n",
    "x_test = np.array(X_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VYoYBcBH31r"
   },
   "outputs": [],
   "source": [
    "# resize data for deep learning\n",
    "x_train = X_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = X_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_test = X_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSvkigbfH347"
   },
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting and handling the imbalance in dataset\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VViqjIhNIA9T"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
    "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjvcvFEkIBAW"
   },
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Civ84BjOIBDW"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(patience=5, factor=0.1, verbose=True),\n",
    "    ModelCheckpoint('best_model.keras', save_best_only=True),\n",
    "    EarlyStopping(patience=12)\n",
    "]\n",
    "\n",
    "history = model.fit(datagen.flow(x_train,y_train, batch_size = 32) ,epochs = 12 , validation_data = datagen.flow(x_val, y_val) ,callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmQ4nkqIIBF_"
   },
   "outputs": [],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yU39rj0ZICGn"
   },
   "outputs": [],
   "source": [
    "epochs = [i for i in range(12)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n",
    "ax[1].set_title('Testing Accuracy & Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Training & Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Zt0S7CVIMSz"
   },
   "outputs": [],
   "source": [
    "# Get the raw probabilities\n",
    "raw_predictions = model.predict(X_test)\n",
    "\n",
    "# Convert to binary class predictions (0 or 1)\n",
    "predictions = (raw_predictions > 0.5).astype(int)\n",
    "\n",
    "# Reshape if needed\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "\n",
    "# Display first 15 predictions\n",
    "print(predictions[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_Md0UZuIMWp"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZgXcEzBIMaL"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYlatNr2IMdX"
   },
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdjkVqELIMgq"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = labels,yticklabels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOI9ll48IQRV"
   },
   "outputs": [],
   "source": [
    "correct = np.nonzero(predictions == y_test)[0]\n",
    "incorrect = np.nonzero(predictions != y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4SwEdHyIQTx"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for c in correct[:6]:\n",
    "    plt.subplot(3,2,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(x_test[c].reshape(150,150), cmap=\"gray\", interpolation='none')\n",
    "    plt.title(f\"Predicted Class {predictions[c]},\\nActual Class {y_test[c]}\")\n",
    "    plt.tight_layout()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RmytGViIQZW"
   },
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/pneumonia_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4474,
     "status": "ok",
     "timestamp": 1743993882091,
     "user": {
      "displayName": "Zhin Kappa",
      "userId": "06338416980234294451"
     },
     "user_tz": 180
    },
    "id": "pv0RQR7wIQcq",
    "outputId": "aa65cf60-e45c-4786-eadf-a9c043f7f31d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
      "PRED: [[3.002677e-06]]\n",
      "Diagnosis: NORMAL (Confidence: 1.00)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "model = load_model('./pneumonia_detection_model.h5')\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Read the image in grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (150, 150))\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Reshape for the model (add batch and channel dimensions)\n",
    "    img = np.reshape(img, (-1, 150, 150, 1))\n",
    "\n",
    "    return img\n",
    "\n",
    "def predict_pneumonia(image_path):\n",
    "    processed_img = preprocess_image(image_path)\n",
    "\n",
    "    prediction = model.predict(processed_img)\n",
    "    print(\"PRED:\",prediction)\n",
    "\n",
    "    # Get result (threshold at 0.5)\n",
    "    result = \"PNEUMONIA\" if prediction[0][0] > 0.5 else \"NORMAL\"\n",
    "    confidence = prediction[0][0] if prediction[0][0] > 0.5 else 1 - prediction[0][0]\n",
    "\n",
    "    return result, confidence\n",
    "\n",
    "img_path = \"IM-0003-0001.jpeg\"\n",
    "result, confidence = predict_pneumonia(img_path)\n",
    "print(f\"Diagnosis: {result} (Confidence: {confidence:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNkhc5g5nrZ7+oQBGtnm9or",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
